{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8499820e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:30.903919Z",
     "iopub.status.busy": "2024-01-06T19:36:30.903499Z",
     "iopub.status.idle": "2024-01-06T19:36:33.108317Z",
     "shell.execute_reply": "2024-01-06T19:36:33.107452Z"
    },
    "papermill": {
     "duration": 2.222337,
     "end_time": "2024-01-06T19:36:33.111025",
     "exception": false,
     "start_time": "2024-01-06T19:36:30.888688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "from os import getcwd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6d8bc",
   "metadata": {
    "papermill": {
     "duration": 0.009589,
     "end_time": "2024-01-06T19:36:33.131052",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.121463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Downoald data to be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88b022c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:33.152470Z",
     "iopub.status.busy": "2024-01-06T19:36:33.151902Z",
     "iopub.status.idle": "2024-01-06T19:36:33.474184Z",
     "shell.execute_reply": "2024-01-06T19:36:33.473174Z"
    },
    "papermill": {
     "duration": 0.335715,
     "end_time": "2024-01-06T19:36:33.476439",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.140724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f92135",
   "metadata": {
    "papermill": {
     "duration": 0.009758,
     "end_time": "2024-01-06T19:36:33.496762",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.487004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Defining two functions:\n",
    "1. `process_tweet`: For preprocessing the tween and removing unnecessary parts.\n",
    "2. `build_freq`: To get the list of all sentences and array of their corresponding sentiment labels and return a dict of this format: `{(word, label): count}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb4d5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:33.518299Z",
     "iopub.status.busy": "2024-01-06T19:36:33.517894Z",
     "iopub.status.idle": "2024-01-06T19:36:33.530234Z",
     "shell.execute_reply": "2024-01-06T19:36:33.529210Z"
    },
    "papermill": {
     "duration": 0.026091,
     "end_time": "2024-01-06T19:36:33.532609",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.506518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            \n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cdad0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:33.554453Z",
     "iopub.status.busy": "2024-01-06T19:36:33.554070Z",
     "iopub.status.idle": "2024-01-06T19:36:33.559317Z",
     "shell.execute_reply": "2024-01-06T19:36:33.558496Z"
    },
    "papermill": {
     "duration": 0.01887,
     "end_time": "2024-01-06T19:36:33.561361",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.542491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c5809c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:33.583029Z",
     "iopub.status.busy": "2024-01-06T19:36:33.582676Z",
     "iopub.status.idle": "2024-01-06T19:36:34.593358Z",
     "shell.execute_reply": "2024-01-06T19:36:34.592450Z"
    },
    "papermill": {
     "duration": 1.024809,
     "end_time": "2024-01-06T19:36:34.596100",
     "exception": false,
     "start_time": "2024-01-06T19:36:33.571291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e45c4",
   "metadata": {
    "papermill": {
     "duration": 0.009605,
     "end_time": "2024-01-06T19:36:34.615767",
     "exception": false,
     "start_time": "2024-01-06T19:36:34.606162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202f49f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:34.637210Z",
     "iopub.status.busy": "2024-01-06T19:36:34.636794Z",
     "iopub.status.idle": "2024-01-06T19:36:34.643060Z",
     "shell.execute_reply": "2024-01-06T19:36:34.642134Z"
    },
    "papermill": {
     "duration": 0.019593,
     "end_time": "2024-01-06T19:36:34.645081",
     "exception": false,
     "start_time": "2024-01-06T19:36:34.625488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22eecc3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:34.666810Z",
     "iopub.status.busy": "2024-01-06T19:36:34.666423Z",
     "iopub.status.idle": "2024-01-06T19:36:34.674565Z",
     "shell.execute_reply": "2024-01-06T19:36:34.673229Z"
    },
    "papermill": {
     "duration": 0.021445,
     "end_time": "2024-01-06T19:36:34.676811",
     "exception": false,
     "start_time": "2024-01-06T19:36:34.655366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n",
    "\n",
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61c8d7",
   "metadata": {
    "papermill": {
     "duration": 0.00999,
     "end_time": "2024-01-06T19:36:34.696771",
     "exception": false,
     "start_time": "2024-01-06T19:36:34.686781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e9288a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:34.717884Z",
     "iopub.status.busy": "2024-01-06T19:36:34.717482Z",
     "iopub.status.idle": "2024-01-06T19:36:39.334042Z",
     "shell.execute_reply": "2024-01-06T19:36:39.332858Z"
    },
    "papermill": {
     "duration": 4.630035,
     "end_time": "2024-01-06T19:36:39.336627",
     "exception": false,
     "start_time": "2024-01-06T19:36:34.706592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11346\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded377c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.360728Z",
     "iopub.status.busy": "2024-01-06T19:36:39.360328Z",
     "iopub.status.idle": "2024-01-06T19:36:39.367871Z",
     "shell.execute_reply": "2024-01-06T19:36:39.366823Z"
    },
    "papermill": {
     "duration": 0.022614,
     "end_time": "2024-01-06T19:36:39.370277",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.347663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "# test the function below\n",
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19473821",
   "metadata": {
    "papermill": {
     "duration": 0.010029,
     "end_time": "2024-01-06T19:36:39.390610",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.380581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a762a890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.414616Z",
     "iopub.status.busy": "2024-01-06T19:36:39.412369Z",
     "iopub.status.idle": "2024-01-06T19:36:39.418999Z",
     "shell.execute_reply": "2024-01-06T19:36:39.418232Z"
    },
    "papermill": {
     "duration": 0.020468,
     "end_time": "2024-01-06T19:36:39.421274",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.400806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    \n",
    "    h = (1/(1 + np.exp(-z)))\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470e81b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.444105Z",
     "iopub.status.busy": "2024-01-06T19:36:39.443731Z",
     "iopub.status.idle": "2024-01-06T19:36:39.450147Z",
     "shell.execute_reply": "2024-01-06T19:36:39.449074Z"
    },
    "papermill": {
     "duration": 0.021599,
     "end_time": "2024-01-06T19:36:39.453479",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.431880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d2770",
   "metadata": {
    "papermill": {
     "duration": 0.010191,
     "end_time": "2024-01-06T19:36:39.474532",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.464341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9f5e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.498577Z",
     "iopub.status.busy": "2024-01-06T19:36:39.498134Z",
     "iopub.status.idle": "2024-01-06T19:36:39.505789Z",
     "shell.execute_reply": "2024-01-06T19:36:39.504718Z"
    },
    "papermill": {
     "duration": 0.022851,
     "end_time": "2024-01-06T19:36:39.508224",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.485373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, lr, epochs):\n",
    "    m = y.shape[0]\n",
    "    print(X.shape, theta.shape, y.shape)\n",
    "    for i in range(epochs):\n",
    "        z = np.dot(X, theta)\n",
    "        y_hat = sigmoid(z)\n",
    "        cost = - (1/m) * np.sum(np.dot(y.T, np.log(y_hat) + np.dot((1 - y).T, np.log(1 - y_hat))))\n",
    "        theta = theta - (lr/m) * np.dot(X.T, (y_hat - y))\n",
    "    return theta, float(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0861829a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.530212Z",
     "iopub.status.busy": "2024-01-06T19:36:39.529828Z",
     "iopub.status.idle": "2024-01-06T19:36:39.578648Z",
     "shell.execute_reply": "2024-01-06T19:36:39.577294Z"
    },
    "papermill": {
     "duration": 0.062286,
     "end_time": "2024-01-06T19:36:39.580874",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.518588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3) (3, 1) (10, 1)\n",
      "The cost after training is 2.29483927.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_theta, tmp_cost = gradient_descent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_cost:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de9dc9",
   "metadata": {
    "papermill": {
     "duration": 0.010331,
     "end_time": "2024-01-06T19:36:39.601721",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.591390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extract tweet freatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54aa86b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.624038Z",
     "iopub.status.busy": "2024-01-06T19:36:39.623623Z",
     "iopub.status.idle": "2024-01-06T19:36:39.630770Z",
     "shell.execute_reply": "2024-01-06T19:36:39.629760Z"
    },
    "papermill": {
     "duration": 0.021066,
     "end_time": "2024-01-06T19:36:39.633005",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.611939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    all = process_tweet(tweet)\n",
    "    \n",
    "    x = np.zeros((1, 3))\n",
    "    # bias\n",
    "    x[0, 0] = 1\n",
    "    \n",
    "    # feature 1: positive summation\n",
    "    x[0, 1] = sum([freqs.get((w, 1), 0) for w in all])\n",
    "    \n",
    "    # feature 2: negative summation\n",
    "    x[0, 2] = sum([freqs.get((w, 0), 0) for w in all])\n",
    "    \n",
    "    assert(x.shape == (1, 3))\n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c08e5d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.656263Z",
     "iopub.status.busy": "2024-01-06T19:36:39.655884Z",
     "iopub.status.idle": "2024-01-06T19:36:39.664097Z",
     "shell.execute_reply": "2024-01-06T19:36:39.663210Z"
    },
    "papermill": {
     "duration": 0.022459,
     "end_time": "2024-01-06T19:36:39.666166",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.643707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 3.02e+03, 6.10e+01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(train_x[0], freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0f228",
   "metadata": {
    "papermill": {
     "duration": 0.010528,
     "end_time": "2024-01-06T19:36:39.687370",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.676842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff59e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:39.709898Z",
     "iopub.status.busy": "2024-01-06T19:36:39.709455Z",
     "iopub.status.idle": "2024-01-06T19:36:45.773076Z",
     "shell.execute_reply": "2024-01-06T19:36:45.771984Z"
    },
    "papermill": {
     "duration": 6.079333,
     "end_time": "2024-01-06T19:36:45.777181",
     "exception": false,
     "start_time": "2024-01-06T19:36:39.697848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 3) (3, 1) (8000, 1)\n",
      "The cost after training is 345.48699932.\n",
      "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "theta, cost = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {cost:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dce48",
   "metadata": {
    "papermill": {
     "duration": 0.022508,
     "end_time": "2024-01-06T19:36:45.823758",
     "exception": false,
     "start_time": "2024-01-06T19:36:45.801250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ab831ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:45.872606Z",
     "iopub.status.busy": "2024-01-06T19:36:45.871933Z",
     "iopub.status.idle": "2024-01-06T19:36:45.880052Z",
     "shell.execute_reply": "2024-01-06T19:36:45.878987Z"
    },
    "papermill": {
     "duration": 0.037726,
     "end_time": "2024-01-06T19:36:45.884142",
     "exception": false,
     "start_time": "2024-01-06T19:36:45.846416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    x = extract_features(tweet, freqs)\n",
    "    \n",
    "    z = np.dot(x, theta)\n",
    "    y_hat = sigmoid(z)\n",
    "    \n",
    "    return int(y_hat > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79471147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:45.910620Z",
     "iopub.status.busy": "2024-01-06T19:36:45.910230Z",
     "iopub.status.idle": "2024-01-06T19:36:45.926233Z",
     "shell.execute_reply": "2024-01-06T19:36:45.924504Z"
    },
    "papermill": {
     "duration": 0.030397,
     "end_time": "2024-01-06T19:36:45.928566",
     "exception": false,
     "start_time": "2024-01-06T19:36:45.898169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Garfyville In Bath? :) Even we don’t have wheelie bins, nowhere to put them @paulmutton\n",
      "Predicted: 1 | True: 1.0\n",
      "\n",
      "I'm so frustrated with my planks. The times are super inconsistent, and I have no idea what I'm doing wrong. :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "@Glanny_ @soL_Lyah @_wattie I told him to suicide and kill both of you, but you ran away forever :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "why won't justin come to Scotland :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "I've run out of bread and I don't feel well enough to make any. :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "I miss those convo's so bad damn :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "@deano042 @RealKrisTravis WHAT :(\n",
      "Predicted: 0 | True: 0.0\n",
      "\n",
      "@anime_narutoINA thank you min :)\n",
      "Predicted: 1 | True: 1.0\n",
      "\n",
      "@namcew make use of the masquerade mask!!!! Lol #zorroreturms :-)\n",
      "Predicted: 1 | True: 1.0\n",
      "\n",
      "@KylieDeVille Happy Birthday!! Enjoy your vacation!:)\n",
      "Predicted: 1 | True: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, len(test_x), size=10)\n",
    "for j in random_idx:\n",
    "    print(test_x[j])\n",
    "    pred = predict_tweet(test_x[j], freqs, theta)\n",
    "    print(f\"Predicted: {pred} | True: {test_y[j][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b35616",
   "metadata": {
    "papermill": {
     "duration": 0.010958,
     "end_time": "2024-01-06T19:36:45.951010",
     "exception": false,
     "start_time": "2024-01-06T19:36:45.940052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64176248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:45.975819Z",
     "iopub.status.busy": "2024-01-06T19:36:45.975432Z",
     "iopub.status.idle": "2024-01-06T19:36:47.165813Z",
     "shell.execute_reply": "2024-01-06T19:36:47.164870Z"
    },
    "papermill": {
     "duration": 1.205571,
     "end_time": "2024-01-06T19:36:47.168413",
     "exception": false,
     "start_time": "2024-01-06T19:36:45.962842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_x), 3))\n",
    "for i in range(len(test_x)):\n",
    "    X_test[i, :]= extract_features(test_x[i], freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0f5f774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:47.192861Z",
     "iopub.status.busy": "2024-01-06T19:36:47.192470Z",
     "iopub.status.idle": "2024-01-06T19:36:47.197766Z",
     "shell.execute_reply": "2024-01-06T19:36:47.196752Z"
    },
    "papermill": {
     "duration": 0.019821,
     "end_time": "2024-01-06T19:36:47.199939",
     "exception": false,
     "start_time": "2024-01-06T19:36:47.180118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    y_hat = sigmoid(z)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45824f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:47.223925Z",
     "iopub.status.busy": "2024-01-06T19:36:47.223544Z",
     "iopub.status.idle": "2024-01-06T19:36:47.230359Z",
     "shell.execute_reply": "2024-01-06T19:36:47.229025Z"
    },
    "papermill": {
     "duration": 0.021283,
     "end_time": "2024-01-06T19:36:47.232578",
     "exception": false,
     "start_time": "2024-01-06T19:36:47.211295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model(X_test, theta)\n",
    "y_pred = (y_pred_proba > 0.5)\n",
    "\n",
    "print(f\"Test Accuracy: {(y_pred == test_y).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b59d67",
   "metadata": {
    "papermill": {
     "duration": 0.067129,
     "end_time": "2024-01-06T19:36:47.310841",
     "exception": false,
     "start_time": "2024-01-06T19:36:47.243712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### My Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38b47660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T19:36:47.338255Z",
     "iopub.status.busy": "2024-01-06T19:36:47.337562Z",
     "iopub.status.idle": "2024-01-06T19:36:47.345591Z",
     "shell.execute_reply": "2024-01-06T19:36:47.344526Z"
    },
    "papermill": {
     "duration": 0.022958,
     "end_time": "2024-01-06T19:36:47.347722",
     "exception": false,
     "start_time": "2024-01-06T19:36:47.324764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tweet(\"@saeid I think today was good for me, beause I've earned 100$.\", freqs, theta)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.38296,
   "end_time": "2024-01-06T19:36:47.980260",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-06T19:36:27.597300",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
